---
layout: post
title: "我的Python之路"
description: ""
category: 
tags: []
---

{% include JB/setup %}
关于爬虫，我希望通过这个简单的小工具可以打开通向Python的大门，简单的背后隐藏着更多值得注意的细节。

目的是去做爬虫，但是现在看来似乎是文件操作，获得url后还需要对地址进行匹配，然后符合条件的进行相应的下载。现在来看似乎还有好多要做的。

{% highlight python %}
#! /usr/bin/python
# Filename: Spider.py
# -*- coding: UTF-8 -*-
# author: David Ding

import urllib
import time 
import os
import re

url = 'http://www.baidu.com';
def getData(url):
	delimiter = '/' # should i use const ?
	fileName = time.strftime( '%Y-%m-%d_%H:%I:%S',time.localtime( time.time() ) ) + '.md'
	filePath = os.getcwd() + delimiter + fileName
	dirPath = os.getcwd() + delimiter + 'data'

	data = urllib.urlopen(url).read()

	if os.path.exists(dirPath):
		pattern = '<a\s*href=\"(.*?)\"'
		res = re.compile(pattern)
		matchs = res.findall(data)
		if matchs != None:
			alist = []
			for found in matchs:
				if found not in alist:
					alist.append(found)

			os.chdir(dirPath)
			fopen = open( fileName, 'w')
			fopen.write(str(alist))
			fopen.close
	else:
		os.mkdir(dirPath)
		print 'make dir'


getData(url)

{% endhighlight %}
